# OptimizaciÃ³n de carteras con aprendizaje por refuerzo profundo (DRL)

Este proyecto implementa un sistema de gestiÃ³n de carteras financieras mediante aprendizaje por refuerzo profundo, entrenado sobre datos de mercado reales. Utiliza un entorno personalizado compatible con Gym y se basa en el algoritmo SAC para entrenar un agente que asigna dinÃ¡micamente pesos entre activos financieros (oro, renta fija, renta variable y efectivo).

> âš ï¸ **Este README es provisional**. AÃºn faltan por completar algunos scripts (`02_explore_data.py`, `05_evaluate_agent.py`). Se actualizarÃ¡ con instrucciones completas en cuanto estÃ©n finalizados.

---

## CÃ³mo ejecutar el proyecto

Todas las acciones relevantes estÃ¡n organizadas en scripts dentro de la carpeta `scripts/`. Cada uno de ellos representa una etapa del flujo completo de trabajo:

### `01_download_data.py`  
Descarga y guarda datos histÃ³ricos de activos financieros (Yahoo Finance) y variables macroeconÃ³micas (FRED).

```bash
python scripts/01_download_data.py
````

---

### `02_explore_data.py`

(En desarrollo) RealizarÃ¡ una exploraciÃ³n inicial de los datos: distribuciÃ³n de retornos, visualizaciÃ³n de variables macro, etc.

---

### `03_test_env.py`

Permite probar el entorno de inversiÃ³n con un agente aleatorio o con reglas fijas, para verificar su correcto funcionamiento.

```bash
python scripts/03_test_env.py
```

---

### `04_train_agent.py`

Entrena un agente con el algoritmo **Soft Actor-Critic (SAC)** utilizando el entorno personalizado. Contiene parÃ¡metros ajustables por el usuario como el tamaÃ±o de la ventana de observaciones, la frecuencia de rebalanceo o el coste de transacciÃ³n. 

```bash
python scripts/04_train_agent.py
```

---

### `05_evaluate_agent.py`

(En desarrollo) PermitirÃ¡ cargar un modelo ya entrenado, evaluar su rendimiento en un conjunto de test y compararlo con estrategias benchmark.

---

## ğŸ“ Estructura de carpetas

```
drl_portfolio/
â”‚
â”œâ”€â”€ scripts/                   # Scripts principales (flujo de usuario)
â”‚   â”œâ”€â”€ 01_download_data.py
â”‚   â”œâ”€â”€ 02_explore_data.py     â† en blanco (pendiente)
â”‚   â”œâ”€â”€ 03_test_env.py
â”‚   â”œâ”€â”€ 04_train_agent.py
â”‚   â”œâ”€â”€ 05_evaluate_agent.py   â† en blanco (pendiente)
â”‚
â”œâ”€â”€ src/                       # LÃ³gica auxiliar y clases internas
â”‚   â”œâ”€â”€ data.py                # Funciones para cargar y preparar datasets
â”‚   â”œâ”€â”€ observation_builder.py # ConstrucciÃ³n del estado observable
â”‚   â”œâ”€â”€ portfolio_env.py       # Entorno personalizado de inversiÃ³n (Gym)
â”‚   â”œâ”€â”€ evaluation.py          # MÃ©tricas: retorno, Sharpe, drawdown, etc.
â”‚
â”œâ”€â”€ models/                    # Modelos entrenados (âš ï¸ generados en tiempo de ejecuciÃ³n)
â”œâ”€â”€ datasets/                  # Archivos de datos descargados y procesados (âš ï¸ autogenerado)
â”œâ”€â”€ results/
â”‚   â”œâ”€â”€ explore_data/          # GrÃ¡ficos y estadÃ­sticas exploratorias
â”‚   â””â”€â”€ model_training/        # Logs de entrenamiento, evoluciÃ³n de mÃ©tricas
```

---

## Estado actual del proyecto

* Entorno Gym personalizado y funcional.
* SAC entrenado con mÃºltiples configuraciones.
* ValidaciÃ³n con ventanas temporales separadas.
* Scripts de exploraciÃ³n y evaluaciÃ³n en construcciÃ³n.
* AnÃ¡lisis detallado de pesos y comparaciÃ³n con benchmarks tradicionales en proceso.

---

## LÃ³gica interna (breve)

* **`portfolio_env.py`** define las reglas del entorno: observaciÃ³n del estado, recompensas, penalizaciÃ³n por rebalanceo.
* **`observation_builder.py`** construye una matriz 3D de observaciones a partir de retornos, indicadores tÃ©cnicos y datos macroeconÃ³micos.
* **`evaluation.py`** implementa mÃ©tricas estÃ¡ndar de rendimiento ajustado por riesgo.
* **`data.py`** maneja la descarga, almacenamiento y estructuraciÃ³n de los datos.